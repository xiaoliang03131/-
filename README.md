é€šè¿‡è½¯ä»¶æå–å¾®ä¿¡èŠå¤©è®°å½•ç„¶åè¿›è¡Œå¯è§†åŒ–åˆ†æ
ä¸‹è½½å¾®ä¿¡èŠå¤©è®°å½•çˆ¬å–ç¨‹åºï¼š

https://github.com/LC044/WeChatMsg/releases/download/v1.0.6/MemoTrace-1.0.6.exe

ç”µè„‘éœ€è¦ç™»å½•å¾®ä¿¡ï¼Œå¦‚æœç”µè„‘å¾®ä¿¡èŠå¤©è®°å½•ä¸é½å…¨ï¼Œå¯ä»¥é€šè¿‡æ‰‹æœºè¿›è¡Œå¾®ä¿¡èŠå¤©è®°å½•è¿ç§»ã€‚

å®‰å“ï¼š æ‰‹æœºå¾®ä¿¡->æˆ‘->è®¾ç½®->èŠå¤©->èŠå¤©è®°å½•è¿ç§»ä¸å¤‡ä»½->è¿ç§»-> è¿ç§»åˆ°ç”µè„‘å¾®ä¿¡ï¼ˆè¿ç§»å®Œæˆåé‡å¯å¾®ä¿¡ï¼‰
iOSï¼š æ‰‹æœºå¾®ä¿¡->æˆ‘->è®¾ç½®->é€šç”¨->èŠå¤©è®°å½•è¿ç§»ä¸å¤‡ä»½->è¿ç§»-> è¿ç§»åˆ°ç”µè„‘å¾®ä¿¡ï¼ˆè¿ç§»å®Œæˆåé‡å¯å¾®ä¿¡ï¼‰
æ‰“å¼€è½¯ä»¶ï¼Œéšåç‚¹å‡»è·å–ä¿¡æ¯ï¼Œè·å–æ‰‹æœºå·ã€å¾®ä¿¡æ˜µç§°ã€wxidç­‰å†…å®¹ï¼Œä¹‹åç‚¹å‡»å¼€å§‹å¯åŠ¨å°±è¡Œã€‚

è‹¥å‡ºç°wxidæˆ–å¾®ä¿¡è·¯å¾„æ— æ³•è·å–é—®é¢˜ï¼ŒæŸ¥çœ‹è§£å†³åŠæ³•ï¼ˆ"ç•™ç—•"ä½¿ç”¨æ•™ç¨‹ (lc044.love)ï¼‰ï¼Œä¸€èˆ¬éƒ½æ˜¯æ²¡é—®é¢˜çš„ã€‚



é€‰æ‹© â€œæ•°æ®  -->  æ‰¹é‡å¯¼å‡ºâ€ï¼Œé€‰æ‹©ä½ æƒ³è¦å¯¼å‡ºçš„è”ç³»äººä¿¡æ¯ã€‚å¯¼å‡ºæ ¼å¼é€‰æ‹©csvæ ¼å¼ï¼Œæ–¹ä¾¿æˆ‘ä»¬åç»­åˆ©ç”¨pythonè¿›è¡Œæ•°æ®åˆ†æï¼š
å¯¼å‡ºåçš„ç»“æœåœ¨ç¨‹åºåŒç›®å½•ä¸‹çš„â€œdata -->  èŠå¤©è®°å½•â€œæ–‡ä»¶ä¸­ï¼Œæˆ‘ä»¬éœ€è¦csvæ–‡ä»¶ï¼Œè®°ä½csvæ–‡ä»¶çš„åœ°å€ï¼Œè‡ªæ­¤å¾®ä¿¡èŠå¤©è®°å½•çˆ¬å–ç»“æŸğŸ‘Œã€‚

äºŒã€å†…å®¹åˆ†æå¯è§†åŒ–å±•ç¤ºï¼š
ç¯å¢ƒé…ç½®ï¼špython3.8ï¼ˆ3.10matplotlibä¸å…¼å®¹é—®é¢˜ï¼‰ numpy pandas seaborn jieba july wordcloud
ä»£ç ä¸­éœ€è¦æ ¹æ®ä½ çš„CSVæ–‡ä»¶åœ°å€ä¿®æ”¹ä»¥åŠèŠå¤©åŒæ–¹åå­—ä¿®æ”¹ï¼š
import matplotlib.pyplot as plt
import pandas as pd
import re
import july
import jieba

from july.utils import date_range
import seaborn as sns
from scipy.stats import norm
import numpy as np

from wordcloud import WordCloud
from collections import Counter


def set_chinese_font():
    # è®¾ç½®ä¸­æ–‡å­—ä½“
    plt.rcParams['font.sans-serif'] = ['SimHei']  # è®¾ç½®ä¸­æ–‡å­—ä½“ä¸ºé»‘ä½“
    plt.rcParams['axes.unicode_minus'] = False  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·


def read_chat_data(file_path):
    # è¯»å–CSVæ–‡ä»¶
    df = pd.read_csv(r'D:\èŠå¤©è®°å½•å­˜æ¡£\data\èŠå¤©è®°å½•\æç§‘æ¡¦(wxid_9p67zxkbfqxa22)\æç§‘æ¡¦.csv')#å°†æ‹¬å·æå–çš„èŠå¤©çš„csvæ–‡ä»¶è·¯å¾„
    return df


def preprocess_data(df):
    # æ•°æ®é¢„å¤„ç†
    df = df[df['Type'] == 1]  # åªä¿ç•™æ–‡æœ¬èŠå¤©
    selected_columns = ['IsSender', 'StrContent', 'StrTime']
    df = df[selected_columns]  # åªå–'IsSender','StrContent','StrTime'åˆ—
    df['StrTime'] = pd.to_datetime(df['StrTime'])
    df['Date'] = df['StrTime'].dt.date
    return df


def plot_chat_frequency_by_day(df):
    # æ¯å¤©èŠå¤©é¢‘ç‡æŸ±çŠ¶å›¾
    chat_frequency = df['Date'].value_counts().sort_index()
    chat_frequency.plot(kind='bar', color='#DF9F9B')
    total_messages = len(df)
    date_labels = [date.strftime('%m-%d') for date in chat_frequency.index]
    plt.text(30, 1300, 'æ¶ˆæ¯æ€»æ•°ï¼š{0}æ¡'.format(total_messages), ha='left', va='top', fontsize=10, color='black')
    plt.text(30, 1250, 'èµ·æ­¢æ—¶é—´ï¼š{0} --- {1}'.format(date_labels[0], date_labels[-1]), ha='left', va='top', fontsize=10,
             color='black')
    plt.xlabel('Date')
    plt.ylabel('Frequency')
    plt.title('Chat Frequency by Day')
    plt.xticks(range(1, len(date_labels), 7), date_labels[::7])
    plt.xticks(fontsize=5)
    plt.show()


def plot_calendar_heatmap(df):
    # åˆ¶ä½œæ—¥å†çƒ­åŠ›å›¾
    df['Date'] = pd.to_datetime(df['Date'])
    start_date = df['Date'].min()
    end_date = df['Date'].max()
    dates = date_range(start_date, end_date)
    july.heatmap(dates=dates,
                 data=df['Date'].value_counts().sort_index(),
                 cmap='Pastel1',
                 month_grid=True,
                 horizontal=True,
                 value_label=False,
                 date_label=False,
                 weekday_label=True,
                 month_label=True,
                 year_label=True,
                 colorbar=False,
                 fontfamily="monospace",
                 fontsize=12,
                 title=None,
                 titlesize='large',
                 dpi=100)
    plt.tight_layout()
    plt.show()


def analyze_message_comparison(df):
    # åŒæ–¹ä¿¡æ¯æ•°é‡å¯¹æ¯”
    sent_by_me = df[df['IsSender'] == 1]['StrContent']
    sent_by_others = df[df['IsSender'] == 0]['StrContent']

    count_sent_by_me = len(sent_by_me)
    count_sent_by_others = len(sent_by_others)

    labels = ['å°æ¢', 'å°åˆ˜']#æ›¿æ¢æˆè‡ªå·±å’ŒèŠå¤©å¯¹è±¡çš„åå­—
    sizes = [count_sent_by_me, count_sent_by_others]
    colors = ['#FF6347', '#9ACD32']
    explode = (0, 0.05)

    plt.rc('font', family='YouYuan')
    plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90)
    plt.axis('equal')
    plt.title('Comparison of the number of chats')
    plt.legend()
    plt.show()


def analyze_hourly_chat_frequency(df):
    # æ ¹æ®ä¸€å¤©ä¸­çš„æ¯ä¸€ä¸ªå°æ—¶è¿›è¡Œç»Ÿè®¡èŠå¤©é¢‘ç‡ï¼Œå¹¶ç”ŸæˆæŸ±çŠ¶å›¾
    df['DateTime'] = pd.to_datetime(df['StrTime'])
    df['Hour'] = df['DateTime'].dt.hour

    hourly_counts = df['Hour'].value_counts().sort_index().reset_index()
    hourly_counts.columns = ['Hour', 'Frequency']

    plt.figure(figsize=(10, 8))
    plt.rc('font', family='YouYuan')
    ax = sns.barplot(x='Hour', y='Frequency', data=hourly_counts, color="#E6AAAA")
    sns.kdeplot(df['Hour'], color='#C64F4F', linewidth=1, ax=ax.twinx())

    plt.title('Chat Frequency by Hour')
    plt.xlabel('Hour of the Day')
    plt.ylabel('Frequency')
    plt.show()


def is_chinese_word(word):
    for char in word:
        if not re.match(r'[\u4e00-\u9fff]', char):
            return False
    return True


def correct(a, stop_words):
    b = []
    for word in a:
        if len(word) > 1 and is_chinese_word(word) and word not in stop_words:
            b.append(word)
    return b


def word_fre_draw(a, str):
    a_counts = Counter(a)
    top_30_a = a_counts.most_common(30)
    words, frequencies = zip(*top_30_a)

    # ç»˜åˆ¶æ°´å¹³æŸ±çŠ¶å›¾
    plt.figure(figsize=(10, 15))
    plt.barh(words, frequencies, color='skyblue')
    plt.xlabel('Frequency')
    plt.ylabel('Words')
    plt.title('Top 30 Words in Chat Messages for {0}'.format(str))
    plt.show()


def word_frequency_analysis(df):
    sent_by_me_text = ' '.join(df[df['IsSender'] == 1]['StrContent'].astype(str))
    sent_by_others_text = ' '.join(df[df['IsSender'] == 0]['StrContent'].astype(str))
    all_text = ' '.join(df['StrContent'].astype(str))

    words = list(jieba.cut(all_text, cut_all=False))
    my_words = list(jieba.cut(sent_by_me_text, cut_all=False))
    others_words = list(jieba.cut(sent_by_others_text, cut_all=False))

    with open(r"D:\Python\å¾®ä¿¡112\cn_stopwords.txt", encoding='utf-8') as f:  #æ›¿æ¢æˆè‡ªå·±çš„åœè¯æ–‡ä»¶è·¯å¾„ï¼Œå°†åœè¯æ–‡ä»¶å’Œä»£ç æ–‡ä»¶æ”¾åœ¨åŒä¸€ä¸ªç›®å½•ä¸‹ï¼Œåœè¯æ–‡ä»¶è‡ªå·±ä¸‹è½½
        con = f.readlines()
        stop_words = set()  # é›†åˆå¯ä»¥å»é‡
        for i in con:
            i = i.replace("\n", "")  # å»æ‰è¯»å–æ¯ä¸€è¡Œæ•°æ®çš„\n
            stop_words.add(i)

    Words = correct(words, stop_words)
    My_words = correct(my_words, stop_words)
    others_words = correct(others_words, stop_words)
    words_space_split = ' '.join(Words)

    word_fre_draw(Words, 'all')#å…±åŒçš„åç§°
    word_fre_draw(My_words, 'å°æ¢')#æ›¿æ¢è‡ªå·±çš„åå­—
    word_fre_draw(others_words, 'å°åˆ˜')#æ›¿æ¢æˆèŠå¤©å¯¹è±¡çš„åå­—
    return words_space_split


def word_cloud(words_space_split):
    wordcloud = WordCloud(font_path='â€ªC:\Windows\Fonts\STCAIYUN.TTF',
                          width=800, height=600,
                          background_color='white',
                          max_words=200,
                          max_font_size=100,
                          ).generate(words_space_split)

    plt.figure(figsize=(10, 8))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    plt.show()


def analyze_weekly_contribution(df):
    df['Weekday'] = df['StrTime'].dt.day_name()

    # è®¡ç®—æ¯å¤©çš„æ¶ˆæ¯æ•°é‡
    weekday_counts = df['Weekday'].value_counts().reindex([
        "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"
    ])

    # æ‰¾å‡ºé¢‘ç‡æœ€é«˜çš„é‚£å¤©
    max_day = weekday_counts.idxmax()

    # åˆ¶ä½œé¥¼çŠ¶å›¾
    plt.figure(figsize=(8, 8))
    explode = [0.1 if day == max_day else 0 for day in weekday_counts.index]  # çªå‡ºæ˜¾ç¤ºé¢‘ç‡æœ€é«˜çš„é‚£å¤©
    plt.pie(weekday_counts, labels=weekday_counts.index, explode=explode, autopct='%1.1f%%',
            startangle=140, colors=plt.cm.Paired.colors)
    plt.title('Distribution of Messages During the Week')
    plt.show()


def analyze_most_active_day_and_month(df):
    df['Date'] = pd.to_datetime(df['Date'])
    df['YearMonth'] = df['Date'].dt.to_period('M')
    df['Day'] = df['Date'].dt.date

    daily_counts = df['Day'].value_counts()
    max_day = daily_counts.idxmax()
    max_day_count = daily_counts.max()

    monthly_counts = df['YearMonth'].value_counts()
    max_month = monthly_counts.idxmax()
    max_month_count = monthly_counts.max()

    print(f"Most active day: {max_day}, with {max_day_count} messages.")
    print(f"Most active month: {max_month}, with {max_month_count} messages.")


if __name__ == "__main__":
    set_chinese_font()
    df = read_chat_data('CSVæ–‡ä»¶')  # åŠ è½½æ•°æ®é›†
    df = preprocess_data(df)  # æ•°æ®é¢„å¤„ç†
    plot_chat_frequency_by_day(df)  # ç»˜åˆ¶æ¯æ—¥èŠå¤©é¢‘ç‡æŸ±çŠ¶å›¾
    plot_calendar_heatmap(df)  # ç»˜åˆ¶æ—¥å†çƒ­åŠ›å›¾
    analyze_message_comparison(df)  # æ¶ˆæ¯å æ¯”å¯¹æ¯”
    analyze_hourly_chat_frequency(df)  # æ¯å°æ—¶èŠå¤©é¢‘ç‡æŸ±çŠ¶å›¾
    words = word_frequency_analysis(df)  # è¯æ±‡é¢‘ç‡åˆ†æ
    word_cloud(words)  # è¯äº‘åˆ¶ä½œ
    analyze_weekly_contribution(df)  # æ¯å‘¨èŠå¤©é¢‘ç‡
    analyze_most_active_day_and_month(df)  # èŠå¤©æœ€å¤šçš„æœˆå’Œå¤©
